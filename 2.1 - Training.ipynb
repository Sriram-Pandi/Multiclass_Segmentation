{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 384\n",
    "width = 512\n",
    "\n",
    "batch_size = 8\n",
    "lr = 1e-4 ## 0.0001\n",
    "epochs = 100\n",
    "num_classes = 8+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset\"\n",
    "\n",
    "files_dir = \"files\"\n",
    "model_file = os.path.join(files_dir, \"unet.h5\")\n",
    "log_file = os.path.join(files_dir, \"log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(files_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention_module(x, ratio=8):\n",
    "    channel = x.shape[-1]\n",
    "    \n",
    "    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n",
    "    l2 = Dense(channel, use_bias=False)\n",
    "    \n",
    "    x1 = GlobalAveragePooling2D()(x)\n",
    "    x1 = l1(x1)\n",
    "    x1 = l2(x1)\n",
    "    \n",
    "    x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = l1(x2)\n",
    "    x2 = l2(x2)\n",
    "    \n",
    "    feats = x1 + x2\n",
    "    feats = Activation(\"sigmoid\")(feats)\n",
    "    \n",
    "    feats = Multiply()([x, feats])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention_module(x):\n",
    "    x1 = tf.reduce_mean(x, axis=-1)\n",
    "    x1 = tf.expand_dims(x1, axis=-1)\n",
    "    \n",
    "    x2 = tf.reduce_max(x, axis=-1)\n",
    "    x2 = tf.expand_dims(x2, axis=-1)\n",
    "    \n",
    "    feats = Concatenate()([x1, x2])\n",
    "    feats = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(feats)\n",
    "    \n",
    "    feats = Multiply()([x, feats])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam(x):\n",
    "    x = channel_attention_module(x)\n",
    "    x = spatial_attention_module(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape, num_classes):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    \"\"\" ResNet50 Encoder \"\"\"\n",
    "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    \n",
    "    s1 = resnet50.get_layer(\"input_1\").output\n",
    "    s2 = resnet50.get_layer(\"conv1_relu\").output\n",
    "    s3 = resnet50.get_layer(\"conv2_block3_out\").output\n",
    "    s4 = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = resnet50.get_layer(\"conv4_block6_out\").output\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4) ##\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"UNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\")))\n",
    "    \n",
    "    valid_x = sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\")))\n",
    "    \n",
    "    return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORMAP = [\n",
    "    [0, 0, 0],\n",
    "    [128, 0, 64],\n",
    "    [192, 0, 192],\n",
    "    [0, 64, 64],\n",
    "    [128, 64, 128],\n",
    "    [192, 0, 0],\n",
    "    [192, 128, 64],\n",
    "    [128, 64, 192],\n",
    "    [192, 128, 192],\n",
    "]\n",
    "\n",
    "new_classes = [\n",
    "    \"Background\",\n",
    "    \"Car\",\n",
    "    \"MotorcycleScooter\",\n",
    "    \"Pedestrian\",\n",
    "    \"Road\",\n",
    "    \"Sidewalk\",\n",
    "    \"SUVPickupTruck\",\n",
    "    \"Train\",\n",
    "    \"Truck_Bus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    \n",
    "    output = []\n",
    "    for color in COLORMAP:\n",
    "        cmap = np.all(np.equal(x, color), axis=-1)\n",
    "        output.append(cmap)\n",
    "    output = np.stack(output, axis=-1)\n",
    "    output = output.astype(np.int64)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "    \n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.int64])\n",
    "    x.set_shape([height, width, 3])\n",
    "    y.set_shape([height, width, num_classes]) ##\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 561 - 561\n",
      "Valid: 70 - 70\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 16:28:19.772127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:19.777085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:19.777856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:19.817677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-27 16:28:19.818622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:19.819379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:19.819956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:20.112410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:20.112917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:20.113395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 16:28:20.113854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21852 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model = build_unet(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 384, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 390, 518, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 192, 256, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 192, 256, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 192, 256, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 194, 258, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 96, 128, 64)  0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 96, 128, 64)  4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 96, 128, 64)  256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 96, 128, 64)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 96, 128, 64)  36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 96, 128, 64)  256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 96, 128, 64)  0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 96, 128, 256  16640       ['pool1_pool[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 96, 128, 256  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 96, 128, 256  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 96, 128, 256  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 96, 128, 256  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 96, 128, 256  0           ['conv2_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 96, 128, 64)  16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 96, 128, 64)  256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 96, 128, 64)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 96, 128, 64)  36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 96, 128, 64)  256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 96, 128, 64)  0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 96, 128, 256  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 96, 128, 256  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 96, 128, 256  0           ['conv2_block1_out[0][0]',       \n",
      "                                )                                 'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 96, 128, 256  0           ['conv2_block2_add[0][0]']       \n",
      "                                )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 96, 128, 64)  16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 96, 128, 64)  256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 96, 128, 64)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 96, 128, 64)  36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 96, 128, 64)  256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 96, 128, 64)  0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 96, 128, 256  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 96, 128, 256  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 96, 128, 256  0           ['conv2_block2_out[0][0]',       \n",
      "                                )                                 'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 96, 128, 256  0           ['conv2_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 48, 64, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 48, 64, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 48, 64, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 48, 64, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 48, 64, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 48, 64, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 48, 64, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 48, 64, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 48, 64, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 48, 64, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 48, 64, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 48, 64, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 48, 64, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 48, 64, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 48, 64, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 48, 64, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 48, 64, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 48, 64, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 48, 64, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 48, 64, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 48, 64, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 48, 64, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 48, 64, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 48, 64, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 48, 64, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 48, 64, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 48, 64, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 48, 64, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 24, 32, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 24, 32, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 24, 32, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 24, 32, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block1_add (Add)         (None, 24, 32, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 24, 32, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 24, 32, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 24, 32, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 24, 32, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 24, 32, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 24, 32, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 24, 32, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 24, 32, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 24, 32, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 24, 32, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 24, 32, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 24, 32, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 24, 32, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 24, 32, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 24, 32, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 24, 32, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 24, 32, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 24, 32, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 24, 32, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 24, 32, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 24, 32, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 24, 32, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 24, 32, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 24, 32, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 24, 32, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 24, 32, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 24, 32, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 24, 32, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 24, 32, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 48, 64, 512)  2097664    ['conv4_block6_out[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 48, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 48, 64, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 48, 64, 512)  2048       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 48, 64, 512)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 48, 64, 512)  2359808     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 48, 64, 512)  2048       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 48, 64, 512)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_1[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 512)         0           ['activation_1[0][0]']           \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           32768       ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_max_pooling2d[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          32768       ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 512)         0           ['dense_1[0][0]',                \n",
      " da)                                                              'dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 512)          0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 48, 64, 512)  0           ['activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 48, 64)      0           ['multiply[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  (None, 48, 64)      0           ['multiply[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 48, 64, 1)    0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 48, 64, 1)    0           ['tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 48, 64, 2)    0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 48, 64, 1)    99          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 48, 64, 512)  0           ['multiply[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 96, 128, 256  524544     ['multiply_1[0][0]']             \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 96, 128, 512  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                )                                 'conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 128, 256  1179904     ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 96, 128, 256  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 96, 128, 256  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 96, 128, 256  590080      ['activation_3[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 96, 128, 256  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 96, 128, 256  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 256)         0           ['activation_4[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 256)         0           ['activation_4[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           8192        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          8192        ['dense_2[0][0]',                \n",
      "                                                                  'dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 256)         0           ['dense_3[0][0]',                \n",
      " mbda)                                                            'dense_3[1][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 256)          0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 96, 128, 256  0           ['activation_4[0][0]',           \n",
      "                                )                                 'activation_5[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.math.reduce_mean_1 (TFOpLam  (None, 96, 128)     0           ['multiply_2[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOpLamb  (None, 96, 128)     0           ['multiply_2[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 96, 128, 1)   0           ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 96, 128, 1)   0           ['tf.math.reduce_max_1[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 96, 128, 2)   0           ['tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.expand_dims_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 96, 128, 1)   99          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 96, 128, 256  0           ['multiply_2[0][0]',             \n",
      "                                )                                 'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 192, 256, 12  131200     ['multiply_3[0][0]']             \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 192, 256, 19  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                2)                                'conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 192, 256, 12  221312      ['concatenate_4[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 192, 256, 12  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 192, 256, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 192, 256, 12  147584      ['activation_6[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 192, 256, 12  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 192, 256, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 128)         0           ['activation_7[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_2 (Global  (None, 128)         0           ['activation_7[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           2048        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          2048        ['dense_4[0][0]',                \n",
      "                                                                  'dense_4[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 128)         0           ['dense_5[0][0]',                \n",
      " mbda)                                                            'dense_5[1][0]']                \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 128)          0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 192, 256, 12  0           ['activation_7[0][0]',           \n",
      "                                8)                                'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 192, 256)    0           ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 192, 256)    0           ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 192, 256, 1)  0           ['tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (None, 192, 256, 1)  0           ['tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 192, 256, 2)  0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.expand_dims_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 192, 256, 1)  99          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 192, 256, 12  0           ['multiply_4[0][0]',             \n",
      "                                8)                                'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 384, 512, 64  32832      ['multiply_5[0][0]']             \n",
      " spose)                         )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 384, 512, 67  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 384, 512, 64  38656       ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 384, 512, 64  256        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 384, 512, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 384, 512, 64  36928       ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 384, 512, 64  256        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 384, 512, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 64)          0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_3 (Global  (None, 64)          0           ['activation_10[0][0]']          \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8)            512         ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           512         ['dense_6[0][0]',                \n",
      "                                                                  'dense_6[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 64)          0           ['dense_7[0][0]',                \n",
      " mbda)                                                            'dense_7[1][0]']                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64)           0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 384, 512, 64  0           ['activation_10[0][0]',          \n",
      "                                )                                 'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 384, 512)    0           ['multiply_6[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_3 (TFOpLamb  (None, 384, 512)    0           ['multiply_6[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (None, 384, 512, 1)  0           ['tf.math.reduce_mean_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLambda)  (None, 384, 512, 1)  0           ['tf.math.reduce_max_3[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 384, 512, 2)  0           ['tf.expand_dims_6[0][0]',       \n",
      "                                                                  'tf.expand_dims_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 384, 512, 1)  99          ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 384, 512, 64  0           ['multiply_6[0][0]',             \n",
      "                                )                                 'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 384, 512, 9)  585         ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,764,501\n",
      "Trainable params: 20,730,069\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "        CSVLogger(log_file),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 16:28:25.875165: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-08-27 16:28:27.736044: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - ETA: 0s - loss: 1.7599 - acc: 0.5965\n",
      "Epoch 1: val_loss improved from inf to 2.10252, saving model to files/unet.h5\n",
      "71/71 [==============================] - 41s 444ms/step - loss: 1.7599 - acc: 0.5965 - val_loss: 2.1025 - val_acc: 0.4198 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 1.1130 - acc: 0.8540\n",
      "Epoch 2: val_loss improved from 2.10252 to 2.09015, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 386ms/step - loss: 1.1130 - acc: 0.8540 - val_loss: 2.0902 - val_acc: 0.2840 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.6173 - acc: 0.8951\n",
      "Epoch 3: val_loss improved from 2.09015 to 2.07214, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 382ms/step - loss: 0.6173 - acc: 0.8951 - val_loss: 2.0721 - val_acc: 0.2793 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.4442 - acc: 0.9139\n",
      "Epoch 4: val_loss improved from 2.07214 to 1.98986, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 387ms/step - loss: 0.4442 - acc: 0.9139 - val_loss: 1.9899 - val_acc: 0.3824 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.3541 - acc: 0.9308\n",
      "Epoch 5: val_loss improved from 1.98986 to 1.79884, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 391ms/step - loss: 0.3541 - acc: 0.9308 - val_loss: 1.7988 - val_acc: 0.5225 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2984 - acc: 0.9396\n",
      "Epoch 6: val_loss improved from 1.79884 to 1.61537, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 385ms/step - loss: 0.2984 - acc: 0.9396 - val_loss: 1.6154 - val_acc: 0.5850 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2617 - acc: 0.9449\n",
      "Epoch 7: val_loss improved from 1.61537 to 1.48289, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 383ms/step - loss: 0.2617 - acc: 0.9449 - val_loss: 1.4829 - val_acc: 0.5853 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2307 - acc: 0.9488\n",
      "Epoch 8: val_loss improved from 1.48289 to 1.45982, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 382ms/step - loss: 0.2307 - acc: 0.9488 - val_loss: 1.4598 - val_acc: 0.5843 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.2076 - acc: 0.9501\n",
      "Epoch 9: val_loss improved from 1.45982 to 0.98852, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 385ms/step - loss: 0.2076 - acc: 0.9501 - val_loss: 0.9885 - val_acc: 0.7777 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1882 - acc: 0.9526\n",
      "Epoch 10: val_loss improved from 0.98852 to 0.79103, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 383ms/step - loss: 0.1882 - acc: 0.9526 - val_loss: 0.7910 - val_acc: 0.8145 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1704 - acc: 0.9547\n",
      "Epoch 11: val_loss did not improve from 0.79103\n",
      "71/71 [==============================] - 26s 366ms/step - loss: 0.1704 - acc: 0.9547 - val_loss: 0.8355 - val_acc: 0.8062 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.9556\n",
      "Epoch 12: val_loss improved from 0.79103 to 0.58610, saving model to files/unet.h5\n",
      "71/71 [==============================] - 29s 400ms/step - loss: 0.1573 - acc: 0.9556 - val_loss: 0.5861 - val_acc: 0.8765 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1446 - acc: 0.9575\n",
      "Epoch 13: val_loss improved from 0.58610 to 0.36535, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 390ms/step - loss: 0.1446 - acc: 0.9575 - val_loss: 0.3653 - val_acc: 0.9205 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1340 - acc: 0.9592\n",
      "Epoch 14: val_loss improved from 0.36535 to 0.30483, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 398ms/step - loss: 0.1340 - acc: 0.9592 - val_loss: 0.3048 - val_acc: 0.9225 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1291 - acc: 0.9599\n",
      "Epoch 15: val_loss improved from 0.30483 to 0.29446, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 391ms/step - loss: 0.1291 - acc: 0.9599 - val_loss: 0.2945 - val_acc: 0.9110 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1210 - acc: 0.9625\n",
      "Epoch 16: val_loss improved from 0.29446 to 0.22495, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 395ms/step - loss: 0.1210 - acc: 0.9625 - val_loss: 0.2249 - val_acc: 0.9349 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1142 - acc: 0.9643\n",
      "Epoch 17: val_loss did not improve from 0.22495\n",
      "71/71 [==============================] - 27s 373ms/step - loss: 0.1142 - acc: 0.9643 - val_loss: 0.2551 - val_acc: 0.9314 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1064 - acc: 0.9672\n",
      "Epoch 18: val_loss improved from 0.22495 to 0.17765, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 389ms/step - loss: 0.1064 - acc: 0.9672 - val_loss: 0.1777 - val_acc: 0.9435 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.1008 - acc: 0.9695\n",
      "Epoch 19: val_loss improved from 0.17765 to 0.16435, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 392ms/step - loss: 0.1008 - acc: 0.9695 - val_loss: 0.1644 - val_acc: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.9715\n",
      "Epoch 20: val_loss improved from 0.16435 to 0.14645, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 394ms/step - loss: 0.0950 - acc: 0.9715 - val_loss: 0.1464 - val_acc: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0871 - acc: 0.9735\n",
      "Epoch 21: val_loss improved from 0.14645 to 0.13069, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 390ms/step - loss: 0.0871 - acc: 0.9735 - val_loss: 0.1307 - val_acc: 0.9603 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0794 - acc: 0.9757\n",
      "Epoch 22: val_loss improved from 0.13069 to 0.12910, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 386ms/step - loss: 0.0794 - acc: 0.9757 - val_loss: 0.1291 - val_acc: 0.9618 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0750 - acc: 0.9766\n",
      "Epoch 23: val_loss improved from 0.12910 to 0.12871, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 380ms/step - loss: 0.0750 - acc: 0.9766 - val_loss: 0.1287 - val_acc: 0.9618 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0734 - acc: 0.9766\n",
      "Epoch 24: val_loss did not improve from 0.12871\n",
      "71/71 [==============================] - 26s 364ms/step - loss: 0.0734 - acc: 0.9766 - val_loss: 0.1335 - val_acc: 0.9599 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0722 - acc: 0.9767\n",
      "Epoch 25: val_loss did not improve from 0.12871\n",
      "71/71 [==============================] - 26s 364ms/step - loss: 0.0722 - acc: 0.9767 - val_loss: 0.1292 - val_acc: 0.9593 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0703 - acc: 0.9772\n",
      "Epoch 26: val_loss improved from 0.12871 to 0.12580, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 383ms/step - loss: 0.0703 - acc: 0.9772 - val_loss: 0.1258 - val_acc: 0.9597 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0671 - acc: 0.9776\n",
      "Epoch 27: val_loss did not improve from 0.12580\n",
      "71/71 [==============================] - 26s 365ms/step - loss: 0.0671 - acc: 0.9776 - val_loss: 0.1297 - val_acc: 0.9606 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.9780\n",
      "Epoch 28: val_loss did not improve from 0.12580\n",
      "71/71 [==============================] - 26s 363ms/step - loss: 0.0649 - acc: 0.9780 - val_loss: 0.1435 - val_acc: 0.9516 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0657 - acc: 0.9779\n",
      "Epoch 29: val_loss did not improve from 0.12580\n",
      "71/71 [==============================] - 26s 363ms/step - loss: 0.0657 - acc: 0.9779 - val_loss: 0.1295 - val_acc: 0.9613 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0639 - acc: 0.9783\n",
      "Epoch 30: val_loss did not improve from 0.12580\n",
      "71/71 [==============================] - 26s 364ms/step - loss: 0.0639 - acc: 0.9783 - val_loss: 0.1374 - val_acc: 0.9590 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0616 - acc: 0.9789\n",
      "Epoch 31: val_loss did not improve from 0.12580\n",
      "71/71 [==============================] - 26s 364ms/step - loss: 0.0616 - acc: 0.9789 - val_loss: 0.1365 - val_acc: 0.9620 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.9777\n",
      "Epoch 32: val_loss improved from 0.12580 to 0.12222, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 388ms/step - loss: 0.0649 - acc: 0.9777 - val_loss: 0.1222 - val_acc: 0.9646 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0584 - acc: 0.9796\n",
      "Epoch 33: val_loss improved from 0.12222 to 0.11860, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 390ms/step - loss: 0.0584 - acc: 0.9796 - val_loss: 0.1186 - val_acc: 0.9654 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0554 - acc: 0.9806\n",
      "Epoch 34: val_loss improved from 0.11860 to 0.11640, saving model to files/unet.h5\n",
      "71/71 [==============================] - 29s 404ms/step - loss: 0.0554 - acc: 0.9806 - val_loss: 0.1164 - val_acc: 0.9656 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0538 - acc: 0.9812\n",
      "Epoch 35: val_loss improved from 0.11640 to 0.11527, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 383ms/step - loss: 0.0538 - acc: 0.9812 - val_loss: 0.1153 - val_acc: 0.9658 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0526 - acc: 0.9815\n",
      "Epoch 36: val_loss improved from 0.11527 to 0.11464, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 385ms/step - loss: 0.0526 - acc: 0.9815 - val_loss: 0.1146 - val_acc: 0.9659 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0517 - acc: 0.9818\n",
      "Epoch 37: val_loss improved from 0.11464 to 0.11425, saving model to files/unet.h5\n",
      "71/71 [==============================] - 27s 383ms/step - loss: 0.0517 - acc: 0.9818 - val_loss: 0.1142 - val_acc: 0.9660 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0510 - acc: 0.9821\n",
      "Epoch 38: val_loss improved from 0.11425 to 0.11411, saving model to files/unet.h5\n",
      "71/71 [==============================] - 28s 392ms/step - loss: 0.0510 - acc: 0.9821 - val_loss: 0.1141 - val_acc: 0.9661 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0503 - acc: 0.9823\n",
      "Epoch 39: val_loss improved from 0.11411 to 0.11397, saving model to files/unet.h5\n",
      "71/71 [==============================] - 29s 399ms/step - loss: 0.0503 - acc: 0.9823 - val_loss: 0.1140 - val_acc: 0.9661 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0497 - acc: 0.9825\n",
      "Epoch 40: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 377ms/step - loss: 0.0497 - acc: 0.9825 - val_loss: 0.1142 - val_acc: 0.9661 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0492 - acc: 0.9826\n",
      "Epoch 41: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 384ms/step - loss: 0.0492 - acc: 0.9826 - val_loss: 0.1143 - val_acc: 0.9661 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0487 - acc: 0.9828\n",
      "Epoch 42: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 372ms/step - loss: 0.0487 - acc: 0.9828 - val_loss: 0.1143 - val_acc: 0.9661 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.9830\n",
      "Epoch 43: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 378ms/step - loss: 0.0483 - acc: 0.9830 - val_loss: 0.1146 - val_acc: 0.9662 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0478 - acc: 0.9831\n",
      "Epoch 44: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 373ms/step - loss: 0.0478 - acc: 0.9831 - val_loss: 0.1147 - val_acc: 0.9662 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0473 - acc: 0.9832\n",
      "Epoch 45: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 368ms/step - loss: 0.0473 - acc: 0.9832 - val_loss: 0.1149 - val_acc: 0.9662 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.9833\n",
      "Epoch 46: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 371ms/step - loss: 0.0472 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.9833\n",
      "Epoch 47: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 369ms/step - loss: 0.0472 - acc: 0.9833 - val_loss: 0.1151 - val_acc: 0.9662 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9833\n",
      "Epoch 48: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 371ms/step - loss: 0.0471 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0471 - acc: 0.9833\n",
      "Epoch 49: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 372ms/step - loss: 0.0471 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 50: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 370ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-07\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 51: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 27s 371ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-07\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 52: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 370ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-07\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 53: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 366ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-07\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 54: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 365ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-07\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 55: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 366ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-08\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 56: val_loss did not improve from 0.11397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 26s 370ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-08\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 57: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 367ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-08\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 58: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 367ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-08\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0470 - acc: 0.9833\n",
      "Epoch 59: val_loss did not improve from 0.11397\n",
      "71/71 [==============================] - 26s 366ms/step - loss: 0.0470 - acc: 0.9833 - val_loss: 0.1150 - val_acc: 0.9662 - lr: 1.0000e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41415d5ab0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
